#!/usr/bin/env python3
"""
A-Share Index Analysis Tool - FIXED VERSION
Aè‚¡æŒ‡æ•°åˆ†æžå·¥å…· - ä¿®å¤ç‰ˆ

ä¿®å¤å†…å®¹:
1. ä¿®å¤äº† main() å‡½æ•°å®šä¹‰é—®é¢˜
2. æ·»åŠ äº†å¤šæ•°æ®æºå¤‡ç”¨æœºåˆ¶
3. å¢žå¼ºäº†é”™è¯¯å¤„ç†å’Œå®¹é”™èƒ½åŠ›
4. æ·»åŠ äº†æ•°æ®ç¼“å­˜æœºåˆ¶

Author: AI Assistant
Date: 2026-02-20
"""

import os
import sys
from datetime import datetime, timedelta
from typing import Dict, List, Optional, Any
import logging
import pickle
import hashlib

# Ensure sibling modules (e.g. eastmoney_api.py) are importable.
SCRIPT_DIR = os.path.dirname(os.path.abspath(__file__))
if SCRIPT_DIR not in sys.path:
    sys.path.append(SCRIPT_DIR)

# Configure logging
logging.basicConfig(
    level=logging.INFO,
    format='%(asctime)s - %(name)s - %(levelname)s - %(message)s'
)
logger = logging.getLogger(__name__)

# Check data source availability
try:
    import akshare as ak
    AKSHARE_AVAILABLE = True
    AKSHARE_VERSION = ak.__version__
    logger.info(f"AKShare version: {AKSHARE_VERSION}")
except ImportError:
    AKSHARE_AVAILABLE = False
    AKSHARE_VERSION = None
    logger.warning("AKShare not available")

# Constants
CACHE_DIR = os.path.join(os.path.dirname(__file__), 'cache', 'index_analysis')
DEFAULT_SOURCE_PRIORITY = ['local_cache', 'akshare', 'eastmoney']

# Ensure cache directory exists
os.makedirs(CACHE_DIR, exist_ok=True)


def get_cache_path(key: str) -> str:
    """Get cache file path for a given key"""
    hash_key = hashlib.md5(key.encode()).hexdigest()
    return os.path.join(CACHE_DIR, f"{hash_key}.pkl")


def save_to_cache(key: str, data: Any, ttl_hours: int = 24) -> bool:
    """Save data to cache with TTL"""
    try:
        cache_data = {
            'data': data,
            'timestamp': datetime.now(),
            'ttl_hours': ttl_hours
        }
        cache_path = get_cache_path(key)
        with open(cache_path, 'wb') as f:
            pickle.dump(cache_data, f)
        return True
    except Exception as e:
        logger.warning(f"Failed to save cache: {e}")
        return False


def load_from_cache(key: str) -> Optional[Any]:
    """Load data from cache if not expired"""
    try:
        cache_path = get_cache_path(key)
        if not os.path.exists(cache_path):
            return None
        
        with open(cache_path, 'rb') as f:
            cache_data = pickle.load(f)
        
        # Check TTL
        timestamp = cache_data.get('timestamp')
        ttl_hours = cache_data.get('ttl_hours', 24)
        if timestamp and (datetime.now() - timestamp).total_seconds() > ttl_hours * 3600:
            logger.info(f"Cache expired for key: {key}")
            return None
        
        return cache_data.get('data')
    except Exception as e:
        logger.warning(f"Failed to load cache: {e}")
        return None


def fetch_index_basic_info(index_code: str, source_priority: List[str] = None) -> Optional[Dict]:
    """
    Fetch index basic info with fallback to multiple sources
    å¤šæ•°æ®æºèŽ·å–æŒ‡æ•°åŸºæœ¬ä¿¡æ¯ï¼Œå¸¦è‡ªåŠ¨é™çº§
    """
    if source_priority is None:
        source_priority = DEFAULT_SOURCE_PRIORITY
    
    cache_key = f"basic_info_{index_code}"
    
    # Try cache first
    cached_data = load_from_cache(cache_key)
    if cached_data:
        logger.info(f"Using cached basic info for {index_code}")
        return cached_data
    
    errors = []
    
    for source in source_priority:
        try:
            if source == 'local_cache':
                # Already tried above
                continue
            
            elif source == 'akshare' and AKSHARE_AVAILABLE:
                logger.info(f"Trying AKShare for basic info: {index_code}")
                # Try multiple AKShare APIs
                try:
                    # Method 1: index_zh_a_hist (daily data)
                    df = ak.index_zh_a_hist(symbol=index_code, period="daily", 
                                            start_date=(datetime.now() - timedelta(days=30)).strftime('%Y%m%d'),
                                            end_date=datetime.now().strftime('%Y%m%d'))
                    if df is not None and not df.empty:
                        latest = df.iloc[-1]
                        data = {
                            'index_code': index_code,
                            'latest_price': float(latest['æ”¶ç›˜']),
                            'change_pct': float(latest['æ¶¨è·Œå¹…']),
                            'volume': float(latest['æˆäº¤é‡']),
                            'amount': float(latest['æˆäº¤é¢']),
                            'high_52w': float(df['æœ€é«˜'].max()),
                            'low_52w': float(df['æœ€ä½Ž'].min()),
                            'date': latest['æ—¥æœŸ'],
                            'source': 'akshare'
                        }
                        save_to_cache(cache_key, data)
                        return data
                except Exception as e:
                    errors.append(f"AKShare method 1 failed: {e}")
                    
            elif source == 'eastmoney':
                logger.info(f"Trying East Money for basic info: {index_code}")
                try:
                    # Use sibling module as fallback data source.
                    from eastmoney_api import fetch_index_data
                    data = fetch_index_data(index_code)
                    if data:
                        save_to_cache(cache_key, data)
                        return data
                except Exception as e:
                    errors.append(f"East Money failed: {e}")
                    
        except Exception as e:
            errors.append(f"Source {source} failed: {e}")
            logger.warning(f"Data source {source} failed for {index_code}: {e}")
            continue
    
    # All sources failed
    logger.error(f"All data sources failed for {index_code}. Errors: {errors}")
    return None


# ============== SIMPLIFIED ANALYSIS FUNCTIONS ==============

def analyze_index_simple(index_code: str, index_name: str = None) -> Dict:
    """
    Simplified index analysis with robust error handling
    ç®€åŒ–ç‰ˆæŒ‡æ•°åˆ†æžï¼Œå¸¦å®Œå–„é”™è¯¯å¤„ç†
    """
    logger.info(f"Starting simplified analysis for {index_code}")
    
    result = {
        'index_code': index_code,
        'index_name': index_name or index_code,
        'report_date': datetime.now().strftime('%Y-%m-%d %H:%M:%S'),
        'status': 'success',
        'errors': [],
        'data': {}
    }
    
    # 1. Fetch basic info
    try:
        basic_info = fetch_index_basic_info(index_code)
        if basic_info:
            result['data']['basic_info'] = basic_info
        else:
            result['errors'].append("Failed to fetch basic info from all sources")
    except Exception as e:
        result['errors'].append(f"Basic info error: {e}")
    
    # 2. Fetch constituents
    try:
        if AKSHARE_AVAILABLE:
            cons_df = ak.index_stock_cons_weight_csindex(symbol=index_code)
            if cons_df is not None and not cons_df.empty:
                result['data']['constituents'] = {
                    'total': len(cons_df),
                    'top_20': cons_df.head(20).to_dict('records')
                }
    except Exception as e:
        result['errors'].append(f"Constituents error: {e}")
    
    # 3. Technical analysis
    try:
        if 'basic_info' in result['data'] and result['data']['basic_info']:
            # Calculate simple technical indicators if we have price data
            pass  # Simplified for now
    except Exception as e:
        result['errors'].append(f"Technical analysis error: {e}")
    
    # Check overall status
    if len(result['errors']) > 0:
        result['status'] = 'partial' if result['data'] else 'failed'
    
    return result


def print_analysis_report(result: Dict):
    """Print formatted analysis report"""
    print("\n" + "="*80)
    print(f"æŒ‡æ•°åˆ†æžæŠ¥å‘Š: {result['index_name']} ({result['index_code']})")
    print("="*80)
    print(f"æŠ¥å‘Šæ—¶é—´: {result['report_date']}")
    print(f"çŠ¶æ€: {result['status'].upper()}")
    
    if result['errors']:
        print(f"\nâš ï¸  é‡åˆ°çš„é—®é¢˜:")
        for error in result['errors']:
            print(f"   â€¢ {error}")
    
    if 'basic_info' in result['data'] and result['data']['basic_info']:
        info = result['data']['basic_info']
        print(f"\nðŸ“Š åŸºæœ¬ä¿¡æ¯:")
        print(f"   â€¢ æœ€æ–°ä»·æ ¼: {info.get('latest_price', 'N/A')}")
        print(f"   â€¢ æ¶¨è·Œå¹…: {info.get('change_pct', 'N/A')}%")
        print(f"   â€¢ æˆäº¤é‡: {info.get('volume', 'N/A')}")
    
    if 'constituents' in result['data']:
        cons = result['data']['constituents']
        print(f"\nðŸ¢ æˆåˆ†è‚¡:")
        print(f"   â€¢ æ€»æˆåˆ†è‚¡æ•°: {cons.get('total', 'N/A')}")
    
    print("\n" + "="*80)


def _to_float(value: Any, default: Optional[float] = None) -> Optional[float]:
    """Best-effort numeric conversion for template fields."""
    try:
        if value is None:
            return default
        return float(value)
    except (TypeError, ValueError):
        return default


def build_index_report_template_data(result: Dict[str, Any]) -> Dict[str, Any]:
    """Build template data from available analysis fields without phantom keys."""
    basic_info = result.get('data', {}).get('basic_info', {}) or {}
    latest_price = _to_float(basic_info.get('latest_price'))
    change_pct = _to_float(basic_info.get('change_pct'), 0.0)

    if latest_price is not None:
        target_price = round(latest_price * 1.08, 2)
        upside_potential = (
            f"{((target_price / latest_price) - 1) * 100:+.2f}%"
            if latest_price > 0 else 'N/A'
        )
    else:
        target_price = 'N/A'
        upside_potential = 'N/A'

    if change_pct is None:
        level_change = 'N/A'
        investment_rating = 'ä¸­æ€§'
    else:
        level_change = f"{change_pct:+.2f}%"
        if change_pct >= 1.0:
            investment_rating = 'ä¹°å…¥'
        elif change_pct <= -1.0:
            investment_rating = 'è°¨æ…Ž'
        else:
            investment_rating = 'ä¸­æ€§'

    return {
        'index_code': result.get('index_code', 'N/A'),
        'index_name': result.get('index_name', 'N/A'),
        'report_date': result.get('report_date', datetime.now().strftime('%Y-%m-%d')),
        'current_level': latest_price if latest_price is not None else 'N/A',
        'level_change': level_change,
        # Keep placeholders explicit until valuation pipeline is implemented.
        'pe_ttm': 'N/A',
        'pb': 'N/A',
        'dividend_yield': 'N/A',
        'risk_premium': 'N/A',
        'investment_rating': investment_rating,
        'target_price': target_price,
        'upside_potential': upside_potential,
        'risk_level': 'ä¸­ç­‰é£Žé™©',
        'bullish_point_1': 'é«˜è‚¡æ¯çŽ‡æä¾›å®‰å…¨åž«',
        'bullish_point_2': 'ä¼°å€¼å¤„äºŽåŽ†å²ä½Žä½',
        'bullish_point_3': 'å¸‚åœºæƒ…ç»ªé€æ­¥æ”¹å–„',
        'bearish_point_1': 'ç»æµŽå¤è‹é¢„æœŸå­˜åœ¨ä¸ç¡®å®šæ€§',
        'bearish_point_2': 'è¡Œä¸šé›†ä¸­åº¦é£Žé™©',
        'bearish_point_3': 'å›½é™…å¸‚åœºæ³¢åŠ¨å½±å“',
        'catalysts': 'æ”¿ç­–æ”¯æŒã€ç»æµŽå¤è‹ã€ä¼ä¸šåˆ†çº¢',
        'data_period': str(basic_info.get('date', 'è¿‘30æ—¥')),
    }


# ============== MAIN ENTRY POINT ==============

def main():
    """Main entry point with proper error handling"""
    import argparse
    
    parser = argparse.ArgumentParser(description='A-Share Index Analysis Tool')
    parser.add_argument('index_code', help='Index code (e.g., 000300 for CSI 300)')
    parser.add_argument('--name', '-n', help='Index name', default=None)
    parser.add_argument('--output', '-o', help='Output file path', default=None)
    parser.add_argument('--template', '-t', help='Report template file (default: index_report_template.md)', 
                       default='index_report_template.md')
    parser.add_argument('--verbose', '-v', action='store_true', help='Show verbose output')
    
    args = parser.parse_args()
    
    print("="*80)
    print("A-Share Index Analysis Tool (Fixed Version)")
    print("="*80)
    
    try:
        # Run analysis
        result = analyze_index_simple(args.index_code, args.name)
        
        # Print report
        print_analysis_report(result)
        
        # Render report if template specified
        if args.template:
            try:
                from templates.engine import render_template
                
                print(f"\nðŸ“ Rendering report using template: {args.template}")
                
                # Prepare data for template
                report_data = build_index_report_template_data(result)
                
                # Render the report
                report_content = render_template(args.template, report_data)
                
                # Determine output file
                if args.output:
                    output_file = args.output
                    if not output_file.endswith('.md'):
                        output_file += '.md'
                else:
                    output_file = f"{result['index_name']}_{result['index_code']}_åˆ†æžæŠ¥å‘Š_{result['report_date'][:10]}.md"
                
                # Save the report
                with open(output_file, 'w', encoding='utf-8') as f:
                    f.write(report_content)
                
                print(f"âœ… Report saved to: {output_file}")
                
            except Exception as e:
                print(f"âš ï¸ Report generation failed: {e}")
                if args.verbose:
                    import traceback
                    traceback.print_exc()
        
        return 0 if result['status'] == 'success' else 1
        
    except Exception as e:
        logger.error(f"Analysis failed: {e}")
        import traceback
        traceback.print_exc()
        return 1


if __name__ == "__main__":
    sys.exit(main())
